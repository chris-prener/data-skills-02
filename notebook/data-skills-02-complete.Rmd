---
title: "Data Skills 02 - Introduction to dplyr for Data Wrangling - Complete"
author: "Christopher Prener, Ph.D."
date: '(`r format(Sys.time(), "%B %d, %Y")`)'
output:
  github_document: default
  html_notebook: default
---

## R Projects and Working Directories
R Projects are a special type of file associated with RStudio. They create self-contained directories and environments that increase the reproducibility of your work. When you set a R project up, it will change the **working directory** to the project's directory. This means that all of the data you save from RStudio will be saved there by default. It also means that you can open files saved in that directory without needing to worry about file paths.

I'll give you an R project directory to download for each session. However, if you want to create a new project for your own work, go to `File > New Project...` and follow the prompts. You can create a new project directory, associate a project with an existing directory, and even add `git` version control!


## Dependencies
This notebook requires two packages from the `tidyverse` as well as two additional packages:

```{r load-packages}
# tidyverse packages
library(dplyr)     # data wrangling
library(readr)     # read and write csv files

# data wrangling
library(janitor)   # data wrangling

# manage file paths
library(here)      # manage file paths
```

## Reading Data
Today, we'll review how to read `.csv` files into `R`. We have to files in the `data/` sub-directory of our project:

1. `penguins.csv` - a cleaner version of the `penguins` data from `palmerpenguins`
2. `penguins_raw.csv` - a messier version of the `penguins` data from `palmerpenguins`

To read `.csv` files into `R`, we'll use the `readr` package's `read_csv()` function. **This is different from `utils::read.csv()`!** 

```{r read-penguins}
penguins <- read_csv(here("data", "penguins.csv"))
```

Now, read in `penguins_raw.csv` into an object called `penguins_raw`:

```{r read-penguins_raw}
penguins_raw <- read_csv(here("data", "penguins_raw.csv"))
```

There is also a package called `readxl` that works well for Excel files and another package called `haven` that can read SPSS, Stata, and SAS data files. Both packages are installed when you install the `tidyverse`.

## Fixing Variable Names
### With `janitor`
One of the issues with both data sets are the variable names. If you have a data set with a large number of columns that you'll want to retain, but many of which need to be renamed, the `janitor` package's `clean_names()` function can help jump start the process.

We'll try out `clean_names()` on the `mpg` data:

```{r clean-names-mpg}
penguins_raw %>%
  clean_names() -> penguins_raw
```

This is a *pipeline*. We can read it like a paragraph, inserting the word *then* every time we see the pipe operator (`%>%`):

1. First, we take the `penguins_raw` data, *then*
2. we clean its names, *then*
3. we store the resulting data in the object `penguins_raw`.

We use pipelines to make our code easier to read.

### With `dplyr`
Ideally, our need to rename variables is more targeted. In that case, we can use `dplyr`'s `rename()` function to modify these names manually:

```{r rename-penguins_raw}
penguins_raw %>%
  rename(
    sid = study_name,
    sample = sample_number,
    iid = individual_id
  ) -> penguins_raw
```

Now, you try on the `penguins` data. Rename `bill_length_mm`, `bill_depth_mm` and `body_mass_g`, ideally removing the units of measure:

```{r rename-penguins}
penguins %>%
  rename(
    bill_length = bill_length_mm,
    bill_depth = bill_depth_mm,
    mass = body_mass_g
  ) -> penguins
```

## Subsetting Columns
We often only want a selection of columns from our data. We can use the `select()` function from `dplyr` to help get us a subset of our data.

```{r subset-penguins_raw}
penguins_raw %>%
  select(species, region, iid, body_mass_g)
```

Now, you try on the `penguins` data. Select only the columns for species, bill length, and bill depth:

```{r subset-penguins}
penguins %>%
  select(species, bill_length, bill_depth)
```

The order here matters! `select()` will reorder your columns to match whatever order you enter them in. You can also remove columns:

```{r subset-penguins_raw-remove}
penguins_raw %>%
  select(-region)
```

## Subsetting Observations
Just like we want only a selection of columns, we may only want a selection of variables. We can use `dplyr`'s `filter()` function to subset our data based on the values observations. To do this, we need one or more of the following operators:

* `>` - greater than
* `>=` -greater than or equal to 
* `<` - less than
* `<=` - less than or equal to 
* `!=` - not equal to 
* `==` - equal to 
* `&` - and
* `|` - or
* `!` - not 

For example, let's pull out all observations in `penguins_raw` that occur either on Biscoe or Dream islands: 

```{r filter-islands}
penguins_raw %>%
  filter(island == "Biscoe" | island == "Dream")
```

Now you try! Let's pull out all observations from `penguins` for Adelie penguins that have a body mass of at least 3700 grams:

```{r filter-adelie}
penguins %>%
  filter(species == "Adelie" & mass >= 3700)
```

## Modifying Variables
If we want to modify an existing variable, or create a new variable, we can use `dplyr`'s `mutate()` function. There are many possible permutations that could build on this, but a simple use case is to create a binary flag for penguins that are over 3700 grams in size:

```{r big-penguin}
penguins_raw %>%
  mutate(big_size = ifelse(body_mass_g >= 3700, TRUE, FALSE)) %>%
  select(body_mass_g, big_size)
```

The `ifelse()` function takes a Boolean condition and then specifies what value to return when it is true and what value to return when it is false. The result of this for each observation is stored in a new variable called `big_size`.

I've added the `select()` function to make it easier to see the changes our `mutate()` function made. In reality, you wouldn't want to add this step unless these were the only two columns you wanted!

Now you try to create a binary indicator variable that is `TRUE` when penguins have a bill length greater than 40mm a mass greater than or equal to 3700 grams:

```{r big-penguin-big-beak}
penguins %>%
  mutate(big_penguin = ifelse(mass >= 3700 & bill_length > 40, TRUE, FALSE)) %>% 
  select(mass, bill_length, big_penguin)
```

With a bit of extra complexity, we might want rename the categories for `species` to be something simpler:

```{r list-species}
unique(penguins_raw$species)
```

If we wanted to simplify these to `adelie`, `gentoo`, and `chinstrap`, we could do the following:

```{r modify-species}
penguins_raw %>% 
  mutate(species_simple = case_when(
    species == "Adelie Penguin (Pygoscelis adeliae)" ~ "adelie",
    species == "Gentoo penguin (Pygoscelis papua)" ~ "gentoo",
    species == "Chinstrap penguin (Pygoscelis antarctica)" ~ "chinstrap"
  )) %>%
  select(species, species_simple)
```

## Putting It All Together
The ideal with pipes is that we can string all of our functions together into a single run:

```{r raw-pipe}
read_csv(here("data", "penguins_raw.csv")) %>%
  clean_names() %>%
  rename(
    sid = study_name,
    sample = sample_number,
    iid = individual_id
  ) %>%
  select(species, island, body_mass_g) %>%
  filter(island == "Biscoe" | island == "Dream") %>%
  mutate(big_size = ifelse(body_mass_g >= 3700, TRUE, FALSE)) %>% 
  mutate(species_simple = case_when(
    species == "Adelie Penguin (Pygoscelis adeliae)" ~ "adelie",
    species == "Gentoo penguin (Pygoscelis papua)" ~ "gentoo",
    species == "Chinstrap penguin (Pygoscelis antarctica)" ~ "chinstrap"
  )) -> penguins_clean
```

If we want to write our data, we can use `write_csv()` from the `readr` package:

```{r write-clean}
write_csv(penguins_clean, here("data", "penguins_clean.csv"))
```
